2020-05-28 21:16:50.906930: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-05-28 21:16:51.188653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6575
pciBusID: 0000:07:00.0
totalMemory: 10.92GiB freeMemory: 10.77GiB
2020-05-28 21:16:51.389727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6575
pciBusID: 0000:0a:00.0
totalMemory: 10.92GiB freeMemory: 10.77GiB
2020-05-28 21:16:51.390794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Device peer to peer matrix
2020-05-28 21:16:51.390831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1051] DMA: 0 1 
2020-05-28 21:16:51.390838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 0:   Y Y 
2020-05-28 21:16:51.390842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 1:   Y Y 
2020-05-28 21:16:51.390849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1)
2020-05-28 21:16:51.390854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)
training with XYZ
Train dataset shape:  (8660, 4096, 6) (8660, 4096)
Test dataset shape:  (0, 4096, 6) (0, 4096)
[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 10988935578), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:1, GPU, 10988935578)]
**** EPOCH 000 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.562679
accuracy: 0.750171
Model saved in file: log3_Retrain_dublin/epoch_0.ckpt
**** EPOCH 001 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.473326
accuracy: 0.786785
**** EPOCH 002 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.450197
accuracy: 0.805162
**** EPOCH 003 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.439114
accuracy: 0.812344
**** EPOCH 004 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.423148
accuracy: 0.822630
**** EPOCH 005 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.406692
accuracy: 0.828448
**** EPOCH 006 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.407487
accuracy: 0.828824
**** EPOCH 007 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.379423
accuracy: 0.839748
**** EPOCH 008 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.382831
accuracy: 0.836918
**** EPOCH 009 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.374671
accuracy: 0.843999
Model saved in file: log3_Retrain_dublin/epoch_9.ckpt
**** EPOCH 010 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.362711
accuracy: 0.843955
**** EPOCH 011 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.352640
accuracy: 0.852778
**** EPOCH 012 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.341967
accuracy: 0.853928
**** EPOCH 013 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.340989
accuracy: 0.856595
**** EPOCH 014 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.337444
accuracy: 0.856459
**** EPOCH 015 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.343500
accuracy: 0.854116
**** EPOCH 016 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.327142
accuracy: 0.860893
**** EPOCH 017 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.334290
accuracy: 0.856713
**** EPOCH 018 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.320384
accuracy: 0.867752
**** EPOCH 019 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.325015
accuracy: 0.861976
Model saved in file: log3_Retrain_dublin/epoch_19.ckpt
**** EPOCH 020 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.325796
accuracy: 0.862683
**** EPOCH 021 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.315326
accuracy: 0.866412
**** EPOCH 022 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.311727
accuracy: 0.867648
**** EPOCH 023 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.318572
accuracy: 0.866603
**** EPOCH 024 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.305976
accuracy: 0.871055
**** EPOCH 025 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.307872
accuracy: 0.872390
**** EPOCH 026 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.307232
accuracy: 0.873715
**** EPOCH 027 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.307532
accuracy: 0.869929
**** EPOCH 028 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.298273
accuracy: 0.873000
**** EPOCH 029 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.308811
accuracy: 0.871226
Model saved in file: log3_Retrain_dublin/epoch_29.ckpt
**** EPOCH 030 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.296739
accuracy: 0.877168
**** EPOCH 031 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.294999
accuracy: 0.876837
**** EPOCH 032 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.293570
accuracy: 0.875930
**** EPOCH 033 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.290993
accuracy: 0.875523
**** EPOCH 034 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.290352
accuracy: 0.876478
**** EPOCH 035 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.294847
accuracy: 0.876652
**** EPOCH 036 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.287137
accuracy: 0.880568
**** EPOCH 037 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.290861
accuracy: 0.875444
**** EPOCH 038 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.293975
accuracy: 0.875109
**** EPOCH 039 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.283353
accuracy: 0.879978
Model saved in file: log3_Retrain_dublin/epoch_39.ckpt
**** EPOCH 040 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.282631
accuracy: 0.878654
**** EPOCH 041 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.284718
accuracy: 0.882169
**** EPOCH 042 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.275311
accuracy: 0.886763
**** EPOCH 043 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.286632
accuracy: 0.877304
**** EPOCH 044 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.277916
accuracy: 0.884470
**** EPOCH 045 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.278497
accuracy: 0.882513
**** EPOCH 046 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.276837
accuracy: 0.883124
**** EPOCH 047 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.274253
accuracy: 0.884869
**** EPOCH 048 ****
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.270618
accuracy: 0.885753
**** EPOCH 049 ****
/home/aji/.conda/envs/aji/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/home/aji/.conda/envs/aji/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/aji/.conda/envs/aji/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/aji/.conda/envs/aji/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/aji/.conda/envs/aji/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/aji/.conda/envs/aji/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/aji/.conda/envs/aji/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/aji/.conda/envs/aji/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
----
Current batch/total batch num: 0/1082
Current batch/total batch num: 100/1082
Current batch/total batch num: 200/1082
Current batch/total batch num: 300/1082
Current batch/total batch num: 400/1082
Current batch/total batch num: 500/1082
Current batch/total batch num: 600/1082
Current batch/total batch num: 700/1082
Current batch/total batch num: 800/1082
Current batch/total batch num: 900/1082
Current batch/total batch num: 1000/1082
mean loss: 0.276811
accuracy: 0.885902
Model saved in file: log3_Retrain_dublin/epoch_49.ckpt
